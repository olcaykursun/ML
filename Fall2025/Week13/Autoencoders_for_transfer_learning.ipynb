{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMVrhomP5ELjaFkjDAAXWgH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olcaykursun/ML/blob/main/Fall2025/Week13/Autoencoders_for_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================\n",
        "# AutoEncoder Pretraining + Small Classifier vs Raw Baseline\n",
        "# AUM Machine Learning - Dr. Olcay Kursun\n",
        "# Simplified Teaching Version (with Visualization + Fine-tuning)\n",
        "# =============================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 0. Setup\n",
        "# -------------------------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 1. Data Loading\n",
        "# -------------------------------------------------------------\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset  = datasets.MNIST(root=\"./data\", train=False, transform=transform)\n",
        "\n",
        "# Many examples for AE pretraining, few for classifier\n",
        "all_indices = torch.randperm(len(train_dataset))\n",
        "ae_indices  = all_indices[:50000]\n",
        "clf_indices = all_indices[50000:50500]  # small labeled subset (500)\n",
        "\n",
        "ae_subset  = Subset(train_dataset, ae_indices)\n",
        "clf_subset = Subset(train_dataset, clf_indices)\n",
        "\n",
        "ae_loader   = DataLoader(ae_subset, batch_size=128, shuffle=True)\n",
        "clf_loader  = DataLoader(clf_subset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 2. AutoEncoder Definition\n",
        "# -------------------------------------------------------------\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        x_hat = self.decoder(z)\n",
        "        return x_hat, z\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 3. AutoEncoder Training\n",
        "# -------------------------------------------------------------\n",
        "def train_autoencoder(model, dataloader, epochs=3):\n",
        "    model.train()\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for imgs, _ in dataloader:\n",
        "            imgs = imgs.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs, _ = model(imgs)\n",
        "            loss = criterion(outputs, imgs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"AE Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n",
        "\n",
        "autoencoder = AutoEncoder().to(device)\n",
        "train_autoencoder(autoencoder, ae_loader, epochs=3)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 3.1. Visualize Reconstruction\n",
        "# -------------------------------------------------------------\n",
        "autoencoder.eval()\n",
        "imgs, _ = next(iter(test_loader))\n",
        "recon, _ = autoencoder(imgs.to(device))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(imgs[0][0], cmap=\"gray\")\n",
        "plt.title(\"Original\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(recon[0][0].detach().cpu(), cmap=\"gray\")\n",
        "plt.title(\"Reconstruction\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 4. Encode Data (Extract Latent Features)\n",
        "# -------------------------------------------------------------\n",
        "def get_encoded(model, loader):\n",
        "    model.eval()\n",
        "    feats, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, lbls in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            _, z = model(imgs)\n",
        "            feats.append(z.view(z.size(0), -1).cpu())\n",
        "            labels.append(lbls)\n",
        "    return torch.cat(feats), torch.cat(labels)\n",
        "\n",
        "x_train, y_train = get_encoded(autoencoder, clf_loader)\n",
        "x_test,  y_test  = get_encoded(autoencoder, test_loader)\n",
        "\n",
        "print(\"Encoded feature shape:\", x_train.shape)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 5. Classifier on Encoded Features\n",
        "# -------------------------------------------------------------\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "clf = Classifier(x_train.shape[1]).to(device)\n",
        "\n",
        "train_data = TensorDataset(x_train, y_train)\n",
        "test_data  = TensorDataset(x_test, y_test)\n",
        "train_loader_clf = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader_clf  = DataLoader(test_data, batch_size=128, shuffle=False)\n",
        "\n",
        "def train_classifier(model, loader, epochs=5):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    for epoch in range(epochs):\n",
        "        total_loss, total_acc = 0, 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            total_acc += (out.argmax(1) == y).float().mean().item()\n",
        "        print(f\"Classifier Epoch {epoch+1}/{epochs}, \"\n",
        "              f\"Loss: {total_loss/len(loader):.4f}, Acc: {total_acc/len(loader):.3f}\")\n",
        "\n",
        "train_classifier(clf, train_loader_clf, epochs=5)\n",
        "\n",
        "# Evaluate classifier\n",
        "clf.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader_clf:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        preds = clf(x).argmax(1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "print(f\"Test accuracy (AE features): {100 * correct / total:.2f}%\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 6. Baseline: CNN Classifier on Raw Pixels (No AE)\n",
        "# -------------------------------------------------------------\n",
        "class ClassifierRaw(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(7 * 7 * 32, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "baseline = ClassifierRaw().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(baseline.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(5):\n",
        "    total_loss, total_acc = 0, 0\n",
        "    for imgs, labels in clf_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = baseline(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        total_acc += (out.argmax(1) == labels).float().mean().item()\n",
        "    print(f\"Baseline Epoch {epoch+1}/5, \"\n",
        "          f\"Loss: {total_loss/len(clf_loader):.4f}, Acc: {total_acc/len(clf_loader):.3f}\")\n",
        "\n",
        "# Evaluate baseline\n",
        "baseline.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        preds = baseline(imgs).argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "print(f\"Test accuracy (raw pixels): {100 * correct / total:.2f}%\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 7. Fine-Tuning: Encoder + Classifier (End-to-End)\n",
        "# -------------------------------------------------------------\n",
        "class EncoderClassifier(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(7*7*32, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.classifier(z)\n",
        "\n",
        "model = EncoderClassifier(autoencoder.encoder).to(device)\n",
        "\n",
        "# Phase 1: Train only the classifier (encoder frozen)\n",
        "for param in model.encoder.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(5):\n",
        "    total_loss, total_acc = 0, 0\n",
        "    for imgs, labels in clf_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        total_acc += (out.argmax(1) == labels).float().mean().item()\n",
        "    print(f\"Fine-tune (frozen) Epoch {epoch+1}/5, \"\n",
        "          f\"Loss: {total_loss/len(clf_loader):.4f}, Acc: {total_acc/len(clf_loader):.3f}\")\n",
        "\n",
        "# Phase 2: Unfreeze encoder and fine-tune all layers\n",
        "for param in model.encoder.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(5):\n",
        "    total_loss, total_acc = 0, 0\n",
        "    for imgs, labels in clf_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        total_acc += (out.argmax(1) == labels).float().mean().item()\n",
        "    print(f\"Fine-tune (all) Epoch {epoch+1}/5, \"\n",
        "          f\"Loss: {total_loss/len(clf_loader):.4f}, Acc: {total_acc/len(clf_loader):.3f}\")\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# Evaluate Encoder+Classifier on Test Set\n",
        "# -------------------------------------------------------------\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        preds = model(imgs).argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "print(f\"Test accuracy (Encoder+Classifier): {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "2pLt87UnpdeS",
        "outputId": "a738168e-e7b5-4b84-c155-654c3a4f25ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "AE Epoch 1/3, Loss: 0.0391\n",
            "AE Epoch 2/3, Loss: 0.0052\n",
            "AE Epoch 3/3, Loss: 0.0040\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded feature shape: torch.Size([500, 1568])\n",
            "Classifier Epoch 1/5, Loss: 2.3653, Acc: 0.261\n",
            "Classifier Epoch 2/5, Loss: 1.4655, Acc: 0.526\n",
            "Classifier Epoch 3/5, Loss: 0.9531, Acc: 0.713\n",
            "Classifier Epoch 4/5, Loss: 0.7209, Acc: 0.832\n",
            "Classifier Epoch 5/5, Loss: 0.5665, Acc: 0.878\n",
            "Test accuracy (AE features): 79.38%\n",
            "Baseline Epoch 1/5, Loss: 2.2648, Acc: 0.129\n",
            "Baseline Epoch 2/5, Loss: 2.1331, Acc: 0.400\n",
            "Baseline Epoch 3/5, Loss: 1.8793, Acc: 0.632\n",
            "Baseline Epoch 4/5, Loss: 1.4814, Acc: 0.718\n",
            "Baseline Epoch 5/5, Loss: 1.0272, Acc: 0.784\n",
            "Test accuracy (raw pixels): 75.31%\n",
            "Fine-tune (frozen) Epoch 1/5, Loss: 2.1240, Acc: 0.367\n",
            "Fine-tune (frozen) Epoch 2/5, Loss: 1.2304, Acc: 0.658\n",
            "Fine-tune (frozen) Epoch 3/5, Loss: 0.8317, Acc: 0.786\n",
            "Fine-tune (frozen) Epoch 4/5, Loss: 0.6303, Acc: 0.853\n",
            "Fine-tune (frozen) Epoch 5/5, Loss: 0.5226, Acc: 0.868\n",
            "Fine-tune (all) Epoch 1/5, Loss: 0.4568, Acc: 0.890\n",
            "Fine-tune (all) Epoch 2/5, Loss: 0.4311, Acc: 0.887\n",
            "Fine-tune (all) Epoch 3/5, Loss: 0.4117, Acc: 0.907\n",
            "Fine-tune (all) Epoch 4/5, Loss: 0.3942, Acc: 0.904\n",
            "Fine-tune (all) Epoch 5/5, Loss: 0.3840, Acc: 0.901\n",
            "Test accuracy (Encoder+Classifier): 84.11%\n"
          ]
        }
      ]
    }
  ]
}