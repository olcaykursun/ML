{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olcaykursun/ML/blob/main/neuralnets/autoencoder_questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26398df5-d3c4-447b-b4f9-a66d26ee5206",
      "metadata": {
        "id": "26398df5-d3c4-447b-b4f9-a66d26ee5206"
      },
      "source": [
        "Using the Iris dataset, perform the following tasks:\n",
        "\n",
        "1. Train a Simple Autoencoder:\n",
        "   - Create an autoencoder with an encoder and a decoder, each having 50 hidden units, the middle (bottleneck) layer will be 10 units.\n",
        "   - The autoencoder architecture should be: 4 input features, maps to 50 hidden units, then compresses to 10 units, then the decoder starts and first expands to 50 hidden units in the decoder, and finally outputs 4 units to match the input.\n",
        "   - Train the autoencoder to learn the 10-dimensional representation of the Iris dataset (use loss='mse').\n",
        "2. Create a Classifier Using the Encoder:\n",
        "   - Use the encoder part of the autoencoder and append a Dense layer with a softmax activation to classify the Iris classes.\n",
        "   - Train this classifier using only 5 examples per class (15 examples in total).\n",
        "3. Train the Standalone Classifier:\n",
        "   - The code below creates a classifier (not using the autoencoder) with a comparable number of layers and units as the autoencoder's encoder plus softmax.\n",
        "   - Train this classifier with the same 5 examples per class.\n",
        "4. Comparison:\n",
        "   - Compare the performance of the classifier built on top of the encoder versus the standalone classifier.\n",
        "   - Which model performs better with such a small training set? Why do you think that is?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e62c1ad-5e86-4064-9e54-c9921263af0a",
      "metadata": {
        "id": "8e62c1ad-5e86-4064-9e54-c9921263af0a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Input\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "x_data = iris.data\n",
        "y_data = to_categorical(iris.target)\n",
        "\n",
        "# Split the dataset into training and testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, train_size=15, random_state=424, stratify=iris.target)\n",
        "\n",
        "# Create a standalone classifier\n",
        "classifier = models.Sequential([\n",
        "    layers.Input(shape=(4,)),\n",
        "    layers.Dense(50, activation='relu'),\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the classifier\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(x_train, y_train, epochs=50, batch_size=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the classifier\n",
        "test_loss, test_acc = classifier.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (tf_metal)",
      "language": "python",
      "name": "tf_metal"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}