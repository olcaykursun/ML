{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olcaykursun/ML/blob/main/neuralnets/autoencoder_answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e62c1ad-5e86-4064-9e54-c9921263af0a",
      "metadata": {
        "id": "8e62c1ad-5e86-4064-9e54-c9921263af0a",
        "outputId": "1e85ccba-112d-46d9-b51a-aef2b5fac35c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-18 10:39:40.530388: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
            "2024-11-18 10:39:40.530430: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2024-11-18 10:39:40.530441: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
            "2024-11-18 10:39:40.530483: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2024-11-18 10:39:40.530505: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
            "2024-11-18 10:39:40.801769: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2231 - accuracy: 0.9481\n",
            "Test accuracy: 0.9481\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Input\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "x_data = iris.data[:,:3]             #I wanted to make it more challenging by using 3 of the features instead of 4.\n",
        "y_data = to_categorical(iris.target)\n",
        "\n",
        "# Split the dataset into training and testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, train_size=15, random_state=42, stratify=iris.target)\n",
        "\n",
        "# Create a standalone classifier\n",
        "classifier = models.Sequential([\n",
        "    layers.Input(shape=(3,)),\n",
        "    layers.Dense(50, activation='relu'),\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the classifier\n",
        "classifier.compile(optimizer='adam',\n",
        "                   loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(x_train, y_train, epochs=300, batch_size=5, verbose=0)\n",
        "\n",
        "# Evaluate the classifier\n",
        "test_loss, test_acc = classifier.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96d0a42c-212f-426f-ad13-acd6ec0932bd",
      "metadata": {
        "id": "96d0a42c-212f-426f-ad13-acd6ec0932bd",
        "outputId": "38d22c34-0e17-469b-f06e-9482b6c011a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4225 - accuracy: 0.9037\n",
            "Test accuracy: 0.9037\n"
          ]
        }
      ],
      "source": [
        "# Create an autoencoder\n",
        "input_layer = Input(shape=(3,))\n",
        "encoded = layers.Dense(50, activation='relu')(input_layer)\n",
        "encoded = layers.Dense(10, activation='relu')(encoded)\n",
        "decoded = layers.Dense(50, activation='sigmoid')(encoded)\n",
        "decoded = layers.Dense(3, activation='linear')(decoded)\n",
        "\n",
        "autoencoder = models.Model(inputs=input_layer, outputs=decoded)\n",
        "\n",
        "# Compile the autoencoder\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(x_data, x_data, epochs=300, verbose=0)\n",
        "\n",
        "# Create a classifier using the encoder part of the autoencoder\n",
        "encoder = models.Model(inputs=input_layer, outputs=encoded)\n",
        "encoder.trainable = False\n",
        "\n",
        "# Add a softmax layer for classification\n",
        "encoded_input = encoder(input_layer)\n",
        "classifier_output = layers.Dense(3, activation='softmax')(encoded_input)\n",
        "classifier = models.Model(inputs=input_layer, outputs=classifier_output)\n",
        "\n",
        "# Compile the classifier\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Warmup the softmax\n",
        "classifier.fit(x_train, y_train, epochs=300, batch_size=5, verbose=0)\n",
        "\n",
        "# Evaluate the classifier\n",
        "test_loss, test_acc = classifier.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "587c841b-84e1-4e7b-80dd-9a8e3936447e",
      "metadata": {
        "id": "587c841b-84e1-4e7b-80dd-9a8e3936447e",
        "outputId": "325b31f5-7331-4b88-e802-454ffd02a1aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1478 - accuracy: 0.9556\n",
            "Test accuracy: 0.9556\n"
          ]
        }
      ],
      "source": [
        "# Unfreeze and recompile the classifier\n",
        "encoder.trainable = True\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Finetune\n",
        "classifier.fit(x_train, y_train, epochs=200, batch_size=5, verbose=0)\n",
        "\n",
        "# Evaluate the classifier\n",
        "test_loss, test_acc = classifier.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n",
        "\n",
        "#Finally we see the benefit of autoencoder\n",
        "#The benefit will be more on more complex problems (that statement maybe tested on MNIST for example)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (tf_metal)",
      "language": "python",
      "name": "tf_metal"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}