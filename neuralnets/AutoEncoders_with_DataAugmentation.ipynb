{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olcaykursun/ML/blob/main/neuralnets/AutoEncoders_with_DataAugmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75358e42-3737-47f3-9581-8c4119542507",
      "metadata": {
        "id": "75358e42-3737-47f3-9581-8c4119542507"
      },
      "source": [
        "<b>AutoEncoders and Data Augmentation for Representation Learning in the Data Domain</b>  \n",
        "AUM Machine Learning, Dr. Olcay Kursun, okursun@aum.edu  \n",
        "Date: 04/11/2024 (Spring 2024)  \n",
        "\n",
        "Description: This script demonstrates autoencoders and data augmentation. Autoencoders are adept at learning efficient representations (or encodings) of the input data by compressing it into a lower-dimensional space and then reconstructing it. This process forces the AutoEncoder to capture the most salient features of the data, which are essential for various tasks like classification, detection, or even generation within the image domain. Data Augmentation further enriches this learning process by introducing variations in the training data, which helps the model to generalize better by learning domain-specific robust features that are invariant to such changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6746f419-75e0-4ba8-b379-48a52b612e00",
      "metadata": {
        "id": "6746f419-75e0-4ba8-b379-48a52b612e00",
        "outputId": "41368d42-da44-41e6-9c0c-3e46f36db58a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data: Reshape and normalize\n",
        "train_images = train_images.reshape((-1, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((-1, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Use a smaller subset for faster training\n",
        "subset_indices = np.random.choice(train_images.shape[0], 500, replace=False)\n",
        "train_images_subset = train_images[subset_indices]\n",
        "train_labels_subset = train_labels[subset_indices]\n",
        "\n",
        "# Function to display a grid of images\n",
        "def display_images(images, labels, num_rows=2, num_cols=5):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    for i in range(num_rows * num_cols):\n",
        "        plt.subplot(num_rows, num_cols, i + 1)\n",
        "        plt.imshow(images[i], cmap='gray')\n",
        "        plt.title(f'Label: {labels[i]}')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display the first few images and their labels\n",
        "display_images(train_images, train_labels.argmax(axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0edc394-d980-46e0-95c1-66af89418eb4",
      "metadata": {
        "id": "d0edc394-d980-46e0-95c1-66af89418eb4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def create_model(use_augmentation=False):\n",
        "    # Define the encoder\n",
        "    input_img = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "    if not use_augmentation:\n",
        "        # Not using the data augmentation layers\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    else:\n",
        "        # Using the data augmentation layers - by default applies only for fit/training and not for predict/inference\n",
        "        x = layers.RandomRotation(factor=0.05)(input_img)  # Randomly rotate images in the range (-5% * 2pi, 5% * 2pi)\n",
        "        x = layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1, 0.1))(x) # Random zoom-in zoom-out\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # Define the decoder\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Autoencoder model\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "    # Extract the encoder\n",
        "    encoder = Model(input_img, encoded)\n",
        "\n",
        "    return autoencoder, encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b482d35-bb2b-4a0f-acd8-5ad5fde0a319",
      "metadata": {
        "id": "0b482d35-bb2b-4a0f-acd8-5ad5fde0a319"
      },
      "outputs": [],
      "source": [
        "def create_classifier_using_encoded_features(encoder):\n",
        "    encoded_input = layers.Input(shape=encoder.output_shape[1:])  # Use encoder's output shape, excluding the batch size\n",
        "    x = layers.Flatten()(encoded_input)  # Flatten the encoded image\n",
        "\n",
        "    # Build the classifier model\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    classifier_output = layers.Dense(10, activation='softmax')(x)  # For MNIST classification\n",
        "\n",
        "    classifier_model = Model(encoded_input, classifier_output)\n",
        "    classifier_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return classifier_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eb663bd-173e-4d2d-b553-663ac012ffd5",
      "metadata": {
        "id": "1eb663bd-173e-4d2d-b553-663ac012ffd5"
      },
      "outputs": [],
      "source": [
        "def test_labeled_subset_with_encoded_features(encoder, classifier_model, test_images, test_labels):\n",
        "    # Transform the test set through the encoder\n",
        "    encoded_imgs_test = encoder.predict(test_images)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    return classifier_model.evaluate(encoded_imgs_test, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2dc4bb2-ebbc-4aef-9d17-3a4600f301bd",
      "metadata": {
        "id": "b2dc4bb2-ebbc-4aef-9d17-3a4600f301bd",
        "outputId": "2712af3e-797b-48a8-c365-8e34a79fa8e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-11 00:45:10.549112: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
            "2024-04-11 00:45:10.549134: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2024-04-11 00:45:10.549139: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
            "2024-04-11 00:45:10.549169: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2024-04-11 00:45:10.549187: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-11 00:45:10.960511: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0847\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0688\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0669\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0659\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0653\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0649\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0646\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0643\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0641\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0639\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 2.2277 - accuracy: 0.2640\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.6846 - accuracy: 0.4200\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.4261 - accuracy: 0.4960\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.2151 - accuracy: 0.6120\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.0787 - accuracy: 0.6420\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.8476 - accuracy: 0.7540\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.7249 - accuracy: 0.7760\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.6181 - accuracy: 0.8300\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.6005 - accuracy: 0.8280\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5897 - accuracy: 0.8100\n",
            "313/313 [==============================] - 0s 1ms/step\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6875 - accuracy: 0.7764\n",
            "test loss without augmentation: 0.6874621510505676\n",
            "test accuracy without augmentation: 0.7764000296592712\n"
          ]
        }
      ],
      "source": [
        "# Create and train the autoencoder without augmentation\n",
        "autoencoder, encoder = create_model()\n",
        "autoencoder.fit(train_images, train_images, epochs=10)\n",
        "\n",
        "# Transform the labeled dataset\n",
        "encoded_imgs = encoder.predict(train_images_subset)\n",
        "\n",
        "# Create and train the classifier on the labeled dataset using the encoder\n",
        "classifier_model = create_classifier_using_encoded_features(encoder)\n",
        "classifier_model.fit(encoded_imgs, train_labels_subset, epochs=10)\n",
        "\n",
        "# Test\n",
        "test_loss, test_acc = test_labeled_subset_with_encoded_features(encoder, classifier_model, test_images, test_labels)\n",
        "print(f\"test loss without augmentation: {test_loss}\")\n",
        "print(f\"test accuracy without augmentation: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77f4fe14-811b-4cae-bcad-4e535b121c90",
      "metadata": {
        "id": "77f4fe14-811b-4cae-bcad-4e535b121c90",
        "outputId": "a652085e-cc9b-4cf4-a66f-e181135c4102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 985us/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.4537 - accuracy: 0.8885\n",
            "test loss with augmentation: 0.45372137427330017\n",
            "test accuracy with augmentation: 0.8884999752044678\n"
          ]
        }
      ],
      "source": [
        "classifier_model.fit(encoded_imgs, train_labels_subset, epochs=100, verbose=0)\n",
        "test_loss, test_acc = test_labeled_subset_with_encoded_features(encoder, classifier_model, test_images, test_labels)\n",
        "print(f\"test loss with augmentation: {test_loss}\")\n",
        "print(f\"test accuracy with augmentation: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b60ffd5a-d526-4149-928f-c5108b3cfb8b",
      "metadata": {
        "id": "b60ffd5a-d526-4149-928f-c5108b3cfb8b",
        "outputId": "b3d43cea-c0bc-4f5d-85ff-a1b11ecfedce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.1531\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1374\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1332\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1307\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1288\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1269\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1253\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.1235\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 29s 16ms/step - loss: 0.1217\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 29s 16ms/step - loss: 0.1202\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 2.2661 - accuracy: 0.1780\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.7708 - accuracy: 0.3560\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.3320 - accuracy: 0.6700\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.0101 - accuracy: 0.7520\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.7517 - accuracy: 0.8260\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5777 - accuracy: 0.8500\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4642 - accuracy: 0.9040\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3856 - accuracy: 0.9220\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3067 - accuracy: 0.9520\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2537 - accuracy: 0.9520\n",
            "313/313 [==============================] - 0s 1ms/step\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3983 - accuracy: 0.8869\n",
            "test loss with augmentation: 0.39829641580581665\n",
            "test accuracy with augmentation: 0.886900007724762\n"
          ]
        }
      ],
      "source": [
        "# Create and train the autoencoder with augmentation\n",
        "autoencoder_aug, encoder_aug = create_model(use_augmentation=True)\n",
        "autoencoder_aug.fit(train_images, train_images, epochs=10)\n",
        "\n",
        "# Transform the labeled dataset\n",
        "encoded_imgs_aug = encoder_aug.predict(train_images_subset)\n",
        "\n",
        "# Create and train the classifier on the labeled dataset using the encoder\n",
        "classifier_model_aug = create_classifier_using_encoded_features(encoder_aug)\n",
        "classifier_model_aug.fit(encoded_imgs_aug, train_labels_subset, epochs=10)\n",
        "\n",
        "# Test\n",
        "test_loss, test_acc = test_labeled_subset_with_encoded_features(encoder_aug, classifier_model_aug, test_images, test_labels)\n",
        "print(f\"test loss with augmentation: {test_loss}\")\n",
        "print(f\"test accuracy with augmentation: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43ec461d-59ce-46a4-a533-7302dbf880f3",
      "metadata": {
        "id": "43ec461d-59ce-46a4-a533-7302dbf880f3",
        "outputId": "7912ef5e-5f75-4e1c-ee56-897f1b8c3c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 983us/step\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2473 - accuracy: 0.9335\n",
            "test loss with augmentation: 0.24732030928134918\n",
            "test accuracy with augmentation: 0.9334999918937683\n"
          ]
        }
      ],
      "source": [
        "if 1: #train the autoencoder for some additional epochs\n",
        "    autoencoder_aug.fit(train_images, train_images, epochs=100)\n",
        "    encoded_imgs_aug = encoder_aug.predict(train_images_subset)\n",
        "\n",
        "#train the classifier for some additional epochs\n",
        "classifier_model_aug.fit(encoded_imgs_aug, train_labels_subset, epochs=10, verbose=0)\n",
        "test_loss, test_acc = test_labeled_subset_with_encoded_features(encoder_aug, classifier_model_aug, test_images, test_labels)\n",
        "print(f\"test loss with augmentation: {test_loss}\")\n",
        "print(f\"test accuracy with augmentation: {test_acc}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (tf_metal)",
      "language": "python",
      "name": "tf_metal"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}